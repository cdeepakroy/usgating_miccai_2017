Automatically generated by Mendeley Desktop 1.13.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Agrawal2010,
abstract = {Conventional low frame rate cameras result in blur and/or aliasing in images while capturing fast dynamic events. Multiple low speed cameras have been used previously with staggered sampling to increase the temporal resolution. However, previous approaches are inefficient: they either use small integration time for each camera which does not provide light benefit, or use large integration time in a way that requires solving a big ill-posed linear system. We propose coded sampling that address these issues: using N cameras it allows N times temporal superresolution while allowing \~{}N/2 times more light compared to an equivalent high speed camera. In addition, it results in a well-posed linear system which can be solved independently for each frame, avoiding reconstruction artifacts and significantly reducing the computational time and memory. Our proposed sampling uses optimal multiplexing code considering additive Gaussian noise to achieve the maximum possible SNR in the recovered video. We show how to implement coded sampling on off-the-shelf machine vision cameras. We also propose a new class of invertible codes that allow continuous blur in captured frames, leading to an easier hardware implementation.},
author = {Agrawal, Amit and Gupta, Mohit and Veeraraghavan, Ashok and Narasimhan, Srinivasa G.},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
issn = {10636919},
pages = {599--606},
title = {{Optimal coded sampling for temporal super-resolution}},
year = {2010}
}

@inproceedings{Akae2012,
abstract = {In this paper, we propose a temporal super resolution ap- proach for quasi-periodic image sequence such as human gait. The proposed method effectively combines example- based and reconstruction-based temporal super resolution approaches. A periodic image sequence is expressed as a manifold parameterized by a phase and a standard mani- fold is learned from multiple high frame-rate sequences in the training stage. In the test stage, an initial phase for each frame of an input low frame-rate image sequence is estimated based on the standard manifold at first, and the manifold reconstruction and the phase estimation are then iterated to generate better high frame-rate images in the energy minimization framework that ensures the fitness to both the input images and the standard manifold. The pro- posed method is applied to low frame-rate gait recognition and experiments with real data of 100 subjects demonstrate a significant improvement by the proposed method, particu- larly for quite low frame-rate videos (e.g., 1 fps).},
author = {Akae, Naoki and Mansur, Al and Makihara, Yasushi and Yagi, Yasushi},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {1537--1543},
title = {{Video from nearly still: An application to low frame-rate gait recognition}},
year = {2012}
}

@article{Alexandrov2012,
author = { Theodore   Alexandrov  and  Silvia   Bianconcini  and  Estela   Bee   Dagum  and  Peter   Maass  and  Tucker   S.   McElroy },
title = {A Review of Some Modern Approaches to the Problem of Trend Extraction},
journal = {Econometric Reviews},
volume = {31},
number = {6},
pages = {593-624},
year = {2012},
doi = {10.1080/07474938.2011.608032},
abstract = { This article presents a review of some modern approaches to trend extraction for one-dimensional time series, which is one of the major tasks of time series analysis. The trend of a time series is usually defined as a smooth additive component which contains information about the time series global change, and we discuss this and other definitions of the trend. We do not aim to review all the novel approaches, but rather to observe the problem from different viewpoints and from different areas of expertise. The article contributes to understanding the concept of a trend and the problem of its extraction. We present an overview of advantages and disadvantages of the approaches under consideration, which are: the model-based approach (MBA), nonparametric linear filtering, singular spectrum analysis (SSA), and wavelets. The MBA assumes the specification of a stochastic time series model, which is usually either an autoregressive integrated moving average (ARIMA) model or a state space model. The nonparametric filtering methods do not require specification of model and are popular because of their simplicity in application. We discuss the Henderson, LOESS, and Hodrick–Prescott filters and their versions derived by exploiting the Reproducing Kernel Hilbert Space methodology. In addition to these prominent approaches, we consider SSA and wavelet methods. SSA is widespread in the geosciences; its algorithm is similar to that of principal components analysis, but SSA is applied to time series. Wavelet methods are the de facto standard for denoising in signal procession, and recent works revealed their potential in trend analysis.}
}

@article{Beaulieu2007,
abstract = {Advances in ultrasound technology continue to enhance its diagnostic applications in daily medical practice. Bedside echocardiographic examination has become useful to properly trained cardiologists, anesthesiologists, intensivists, surgeons, and emergency room physicians. Cardiac ultrasound can permit rapid, accurate, and noninvasive diagnosis of a broad range of acute cardiovascular pathologies. Although transesophageal echocardiography was once the principal diagnostic approach using ultrasound to evaluate intensive care unit patients, advances in ultrasound imaging, including harmonic imaging, digital acquisition, and contrast for endocardial enhancement, has improved the diagnostic yield of transthoracic echocardiography. Ultrasound devices continue to become more portable, and hand-carried devices are now readily available for bedside applications. This article discusses the application of bedside echocardiography in the intensive care unit. The emphasis is on echocardiography and cardiovascular diagnostics, specifically on goal-directed bedside cardiac ultrasonography.},
author = {Beaulieu, Yanick},
doi = {10.1097/01.CCM.0000260673.66681.AF},
isbn = {0000260673},
issn = {0090-3493},
journal = {Critical care medicine},
pages = {S235--S249},
pmid = {17446784},
title = {{Bedside echocardiography in the assessment of the critically ill.}},
volume = {35},
year = {2007}
}

@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
isbn = {9780387310732},
issn = {10179909},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
volume = {4},
year = {2006}
}

@ARTICLE{Boashash1992, 
author={B. Boashash}, 
journal={Proceedings of the IEEE}, 
title={Estimating and interpreting the instantaneous frequency of a signal. II. Algorithms and applications}, 
year={1992}, 
volume={80}, 
number={4}, 
pages={540-568}, 
abstract={For pt.I see ibid., vol.80, no.4, p.520-38 (1992). The concept of instantaneous frequency (IF) is extended to discrete-time signals. The specific problem explored is that of estimating the IF of frequency-modulated (FM) discrete-time signals embedded in Gaussian noise. Well-established methods for estimating the IF include differentiation of the phase and smoothing thereof, adaptive frequency estimation techniques such as the phase locked loop (PLL), and extraction of the peak from time-varying spectral representations. More recently, methods based on a modeling of the signal phase as a polynomial have been introduced. These methods are reviewed, and their performance compared on both simulated and real data. Guidelines are given as to which estimation method should be used for a given signal class and signal-to-noise ratio (SNR)}, 
keywords={phase-locked loops;random noise;signal processing;spectral analysis;FM;Gaussian noise;adaptive frequency estimation;differentiation;discrete-time signals;instantaneous frequency;phase;phase locked loop;signal class;signal-to-noise ratio;smoothing;time-varying spectral representations;Frequency estimation;Frequency modulation;Gaussian noise;Phase estimation;Phase locked loops;Polynomials;Signal analysis;Signal processing;Signal processing algorithms;Smoothing methods}, 
doi={10.1109/5.135378}, 
ISSN={0018-9219}, 
month={Apr}
}

@article{Bouwmans2014,
abstract = {Foreground detection is the first step in video surveillance system to detect moving objects. Recent research on subspace estimation by sparse representation and rank minimization represents a nice framework to separate moving objects from the background. Robust Principal Component Analysis (RPCA) solved via Principal Component Pursuit decomposes a data matrix A in two components such that A=L+S, where L is a low-rank matrix and S is a sparse noise matrix. The background sequence is then modeled by a low-rank subspace that can gradually change over time, while the moving foreground objects constitute the correlated sparse outliers. To date, many efforts have been made to develop Principal Component Pursuit (PCP) methods with reduced computational cost that perform visually well in foreground detection. However, no current algorithm seems to emerge and to be able to simultaneously address all the key challenges that accompany real-world videos. This is due, in part, to the absence of a rigorous quantitative evaluation with synthetic and realistic large-scale dataset with accurate ground truth providing a balanced coverage of the range of challenges present in the real world. In this context, this work aims to initiate a rigorous and comprehensive review of RPCA-PCP based methods for testing and ranking existing algorithms for foreground detection. For this, we first review the recent developments in the field of RPCA solved via Principal Component Pursuit. Furthermore, we investigate how these methods are solved and if incremental algorithms and real-time implementations can be achieved for foreground detection. Finally, experimental results on the Background Models Challenge (BMC) dataset which contains different synthetic and real datasets show the comparative performance of these recent methods. ?? 2013 Elsevier Inc. All rights reserved.},
author = {Bouwmans, Thierry and Zahzah, El Hadi},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Foreground detection,Principal Component Pursuit,Robust principal component analysis},
pages = {22--34},
title = {{Robust PCA via Principal Component Pursuit: A review for a comparative evaluation in video surveillance}},
volume = {122},
year = {2014}
}

@misc{Buades2005,
abstract = {The search for efficient image denoising methods is still a valid challenge at the crossing of functional analysis and statistics. In spite of the sophistication of the recently proposed methods, most algorithms have not yet attained a desirable level of applicability. All show an outstanding performance when the image model corresponds to the algorithm assumptions but fail in general and create artifacts or remove image fine structures. The main focus of this paper is, first, to define a general mathematical and experimental methodology to compare and classify classical image denoising algorithms and, second, to propose a nonlocal means (NL-means) algorithm addressing the preservation of structure in a digital image. The mathematical analysis is based on the analysis of the "method noise," defined as the difference between a digital image and its denoised version. The NL-means algorithm is proven to be asymptotically optimal under a generic statistical image model. The denoising performance of all consid...},
author = {Buades, A. and Coll, B. and Morel, J. M.},
booktitle = {Multiscale Modeling \& Simulation},
isbn = {0769523722},
issn = {1540-3459},
pages = {490--530},
pmid = {231665400006},
title = {{A Review of Image Denoising Algorithms, with a New One}},
volume = {4},
year = {2005}
}

@article{Burges2009,
author = {Burges, Christopher J C},
doi = {10.1561/2200000002},
issn = {1935-8237},
journal = {Foundations and Trends® in Machine Learning},
keywords = {Dimensionality reduction},
number = {4},
pages = {275--365},
publisher = {Now Publishers},
title = {{Dimension Reduction: A Guided Tour}},
volume = {2},
year = {2009}
}

@article{Candes2009,
abstract = {This paper is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the L1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.},
archivePrefix = {arXiv},
arxivId = {arXiv:0912.3599v1},
author = {Cand\`{e}s, Emmanuel J and Li, Xiaodong and Ma, Yi and Wright, John and Candes, Emmanuel J},
eprint = {arXiv:0912.3599v1},
institution = {Department of Statistics, Stanford University},
isbn = {0-7803-6278-0},
issn = {0004-5411},
journal = {Journal of the ACM},
keywords = {\&ell,1-norm minimization,Principal components,duality,low-rank matrices,nuclear-norm minimization,robustness vis-a-vis outliers,sparsity,video surveillance},
number = {3},
pages = {1--37},
publisher = {ACM Request Permissions},
title = {{Robust Principal Component Analysis?}},
volume = {58},
year = {2009}
}

@article{Chatterjee2010,
abstract = {Image denoising has been a well studied problem in the field of image processing. Yet researchers continue to focus attention on it to better the current state-of-the-art. Recently proposed methods take different approaches to the problem and yet their denoising performances are comparable. A pertinent question then to ask is whether there is a theoretical limit to denoising performance and, more importantly, are we there yet? As camera manufacturers continue to pack increasing numbers of pixels per unit area, an increase in noise sensitivity manifests itself in the form of a noisier image. We study the performance bounds for the image denoising problem. Our work in this paper estimates a lower bound on the mean squared error of the denoised result and compares the performance of current state-of-the-art denoising methods with this bound. We show that despite the phenomenal recent progress in the quality of denoising algorithms, some room for improvement still remains for a wide class of general images, and at certain signal-to-noise levels. Therefore, image denoising is not dead--yet.},
author = {Chatterjee, Priyam and Milanfar, Peyman},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Bayesian Cram\&r\&Rao lower bound (CRLB),Bias,Bootstrapping,Image denoising,Mean squared error},
number = {4},
pages = {895--911},
pmid = {19932997},
title = {{Is denoising dead?}},
volume = {19},
year = {2010}
}

@article{Cleveland1988,
abstract = {Abstract Locally weighted regression, or loess, is a way of estimating a regression surface through a multivariate smoothing procedure, fitting a function of the independent variables locally and in a moving fashion analogous to how a moving average is computed for a time series. With local fitting we can estimate a much wider class of regression surfaces than with the usual classes of parametric functions, such as polynomials. The goal of this article is to show, through applications, how loess can be used for three purposes: data exploration, diagnostic checking of parametric models, and providing a nonparametric regression surface. Along the way, the following methodology is introduced: (a) a multivariate smoothing procedure that is an extension of univariate locally weighted regression; (b) statistical procedures that are analogous to those used in the least-squares fitting of parametric functions; (c) several graphical methods that are useful tools for understanding loess estimates and checking the assumptions on which the estimation procedure is based; and (d) the M plot, an adaptation of Mallows's Cp procedure, which provides a graphical portrayal of the trade-off between variance and bias, and which can be used to choose the amount of smoothing.},
annote = {doi: 10.1080/01621459.1988.10478639},
author = {Cleveland, William S and Devlin, Susan J},
doi = {10.1080/01621459.1988.10478639},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = sep,
number = {403},
pages = {596--610},
publisher = {Taylor \& Francis},
title = {{Locally Weighted Regression: An Approach to Regression Analysis by Local Fitting}},
volume = {83},
year = {1988}
}

@article{Cleveland1990,
abstract = {STL is a filtering procedure for decomposing a time series into trend, seasonal, and remainder components. STL has a simple design that consists of a sequence of applications of the loess smoother; the simplicity allows analysis of the properties of the procedure and allows fast computation, even for very long time series and large amounts of trend and seasonal smoothing. Other features of STL are specification of amounts of seasonal and trend smoothing that range, in a nearly continuous way, from a very small amount of smoothing to a very large amount; robust estimates of the trend and seasonal components that are not distorted by aberrant behavior in the data; specification of the period of the seasonal component to any integer multiple of the time sampling interval greater than one; and the ability to decompose time series with missing values.},
author = {Cleveland, Robert B and Cleveland, William S and McRae, Jean E and Terpenning, Irma},
file = {:home/cdeepakroy/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cleveland et al. - 1990 - STL A seasonal-trend decomposition procedure based on loess.pdf:pdf},
issn = {0282-423X},
journal = {Journal of Official Statistics},
number = {1},
pages = {3--73},
title = {{STL: A seasonal-trend decomposition procedure based on loess}},
volume = {6},
year = {1990}
}

@article{Cootney2001,
author = {Cootney, R. W.},
doi = {10.1093/ilar.42.3.233},
file = {:home/cdeepakroy/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cootney - 2001 - Ultrasound Imaging Principles and Applications in Rodent Research.pdf:pdf},
issn = {1084-2020},
journal = {ILAR Journal},
keywords = {echocardiography,mice,rats,research,ultra-},
month = jan,
number = {3},
pages = {233--247},
title = {{Ultrasound Imaging: Principles and Applications in Rodent Research}},
url = {http://ilarjournal.oxfordjournals.org/cgi/doi/10.1093/ilar.42.3.233},
volume = {42},
year = {2001}
}

@article{Cutler2000,
abstract = {We describe new techniques to detect and analyze periodic motion as seen from both a static and a moving camera. By tracking objects of interest, we compute an object's self-similarity as it evolves in time. For periodic motion, the self-similarity measure is also periodic and we apply time-frequency analysis to detect and characterize the periodic motion. The periodicity is also analyzed robustly using the 2D lattice structures inherent in similarity matrices. A real-time system has been implemented to track and classify objects using periodicity. Examples of object classification (people, running dogs, vehicles), person counting,},
author = {Cutler, R and Davis, L S},
doi = {10.1109/CVPR.1999.784652},
isbn = {0769501494},
issn = {10636919},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {8},
pages = {781--796},
title = {{Robust real-time periodic motion detection, analysis, and applications}},
volume = {22},
year = {2000}
}

@incollection{Goshtasby2012,
abstract = {The topics of similarity and dissimilarity measures are discussed in detail. The chapter starts with definitions of similarity and dissimilarity measures and lists the requirements for them to be metrics. In addition to the existing similarity and dissimilarity measures, 3 new similarity measures and 1 new dissimilarity measure are introduced. The performances of 16 similarity measures and 10 dissimilarity measures in image matching are determined and compared, and their sensitivities to noise and blurring as well as to intensity and geometric changes are also determined and compared. The similarity measures tested are Pearson correlation, Tanimoto measure, stochastic sign change, deterministic sign change, minimum ratio, Spearman’s $\rho$, Kendall’s $\tau$, greatest deviation, ordinal measure, correlation ratio, energy of joint probability density, material similarity, Shannon mutual information, R\'{e}nyi mutual information, Tsallis mutual information, and I $\alpha$ information. The dissimilarity measures tested are L 1 norm, median of absolute differences, square L 2 norm, median of square differences, normalized square L 2 norm, incremental sign distance, intensity-ratio variance, intensity-mapping-ratio variance, rank distance, joint entropy, and exclusive F-information.},
author = {Goshtasby, A.Ardeshir},
booktitle = {Image Registration SE - 2},
doi = {10.1007/978-1-4471-2458-0\_2},
isbn = {978-1-4471-2457-3},
language = {English},
pages = {7--66},
publisher = {Springer London},
series = {Advances in Computer Vision and Pattern Recognition},
title = {{Similarity and Dissimilarity Measures}},
year = {2012}
}

@article{Kuklik2015,
abstract = {The Hilbert transform has been used to characterize wave propagation and detect phase singularities during cardiac fibrillation. Two mapping modalities have been used: optical mapping (used to map atria and ventricles) and contact electrode mapping (used only to map ventricles). Due to specific morphology of atrial electrograms, phase reconstruction of contact electrograms in the atria is challenging and has not been investigated in detail. Here, we explore the properties of Hilbert transform applied to unipolar epicardial electrograms and devise a method for robust phase reconstruction using the Hilbert transform. We applied the Hilbert transform to idealized unipolar signals obtained from analytical approach and to electrograms recorded in humans. We investigated effects of deflection morphology on instantaneous phase. Application of the Hilbert transform to unipolar electrograms demonstrated sensitivity of reconstructed phase to the type of deflection morphology (uni- or biphasic), the ratio of R and S waves and presence of the noise. In order to perform a robust phase reconstruction, we propose a signal transformation based on the recomposition of the electrogram from sinusoidal wavelets with amplitudes proportional to the negative slope of the electrogram. Application of the sinusoidal recomposition transformation prior to application of the Hilbert transform alleviates the effect of confounding features on reconstructed phase.},
author = {Kuklik, Pawel and Zeemering, Stef and Maesen, Bart and Maessen, Jos and Crijns, Harry J and Verheule, Sander and Ganesan, Anand N and Schotten, Ulrich},
doi = {10.1109/TBME.2014.2350029},
issn = {1558-2531 (Electronic)},
journal = {IEEE transactions on bio-medical engineering},
language = {eng},
month = jan,
number = {1},
pages = {296--302},
pmid = {25148659},
title = {{Reconstruction of instantaneous phase of unipolar atrial contact electrogram using a concept of sinusoidal recomposition and Hilbert transform.}},
volume = {62},
year = {2015}
}

@article{Laptev2005,
abstract = { A method for detecting and segmenting periodic motion is presented. We exploit periodicity as a cue and detect periodic motion in complex scenes where common methods for motion segmentation are likely to fail. We note that periodic motion detection can be seen as an approximate case of sequence alignment where an image sequence is matched to itself over one or more periods of time. To use this observation, we first consider alignment of two video sequences obtained by independently moving cameras. Under assumption of constant translation, the fundamental matrices and the homographies are shown to be time-linear matrix functions. These dynamic quantities can be estimated by matching corresponding space-time points with similar local motion and shape. For periodic motion, we match corresponding points across periods and develop a RANSAC procedure to simultaneously estimate the period and the dynamic geometric transformations between periodic views. Using this method, we demonstrate detection and segmentation of human periodic motion in complex scenes with nonrigid backgrounds, moving camera and motion parallax.},
author = {Laptev, I. and Belongie, S.J. and Perez, P. and Wills, J.},
journal = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
title = {{Periodic motion detection and segmentation via approximate sequence alignment}},
volume = {1},
year = {2005}
}

@article{Lin2010,
archivePrefix = {arXiv},
arxivId = {math.OC/1009.5055},
author = {Lin, Z and Chen, M and Ma, Y},
eprint = {1009.5055},
journal = {ArXiv e-prints},
keywords = {Computer Science - Numerical Analysis,Computer Science - Systems and Control,Mathematics - Optimization and Control},
month = sep,
primaryClass = {math.OC},
title = {{The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices}},
year = {2010}
}

@article{Lu2013,
abstract = {The instantaneous phase estimated by the Hilbert transform (HT) is susceptible to noise; we propose a robust approach for the estimation of instantaneous phase in noisy situations. The main procedure of the proposed method is applying an adaptive filter in time-frequency domain and calculating the analytic signal. By supposing that one frequency component with higher amplitude has higher signal-to-noise ratio, a zero-phase adaptive filter, which is constructed by using the time-frequency amplitude spectrum, enhances the frequency components with higher amplitudes and suppresses those with lower amplitudes. The estimation of instantaneous frequency, which is defined as the derivative of instantaneous phase, is also improved by the proposed robust instantaneous phase estimation method. Synthetic and field data sets are used to demonstrate the performance of the proposed method for the estimation of instantaneous phase and frequency, compared by the HT and short-time-Fourier-transform methods. © 2012 Society of Exploration Geophysicists.},
author = {Lu, Wen-kai and Zhang, Chang-Kai},
doi = {10.1190/geo2011-0435.1},
issn = {0016-8033},
journal = {GEOPHYSICS},
number = {1},
pages = {O1--O7},
title = {{Robust estimation of instantaneous phase using a time-frequency adaptive filter}},
volume = {78},
year = {2013}
}

@article {Luo2003,
author = {Luo, Yi and Al-Dossary, Saleh and Marhoon, Maher and Alfaraj, Mohammad},
title = {Generalized Hilbert transform and its applications in geophysics},
volume = {22},
number = {3},
pages = {198--202},
year = {2003},
doi = {10.1190/1.1564522},
publisher = {GeoScienceWorld},
issn = {1070-485X},
journal = {The Leading Edge}
}

@inproceedings{Makihara2011,
abstract = {This paper describes a method for temporal super resolution from a single quasi-periodic image sequence. A so-called reconstruction-based method is applied to construct a one period image sequence with high frame-rate based on phase registration data in sub-frame order among multiple periods of the image sequence. First, the periodic image sequence to be reconstructed is expressed as a manifold in the parametric eigenspace of the phase. Given an input image sequence, phase registration and manifold reconstruction are alternately executed iteratively within an energy minimization framework that considers data fitness and the smoothness of both the manifold and the phase evolution. The energy minimization problem is solved through three-step coarse-to-fine procedures to avoid local minima. The experiments using both simulated and real data confirm the realization of temporal super resolution from a single image sequence.},
author = {Makihara, Yasushi and Mori, Atsushi and Yagi, Yasushi},
booktitle = {Computer Vision--ACCV 2010},
pages = {107--120},
title = {{Temporal super resolution from a single quasi-periodic image sequence based on phase registration}},
year = {2011}
}

@article{Makihara2014,
abstract = {We propose a method for phase estimation of a single non-parametric quasi-periodic signal. Assuming signal intensities should be equal among samples of the same phase, such corresponding samples are obtained by self-dynamic time warping between a quasi-periodic signal and a signal with multiple-period shifts applied. A phase sequence is then estimated in a sub-sampling order using an optimization framework incorporating 1) a data term derived from the correspondences and 2) a smoothness term of the local phase evolution under 3) a monotonic-increasing constraint on the phase. Such a phase estimation is, however, ill-posed because of combination ambiguity between the phase evolution and the normalized periodic signal, and hence can result in a biased solution. Therefore, we introduce into the optimization framework 4) a bias correction term, which imposes zero-bias from the linear phase evolution. Analysis of the quasi-periodic signals from both simulated and real data indicate the effectiveness and also potential applications of the proposed method.},
author = {Makihara, Yasushi and Aqmar, Muhammad Rasyid and Trung, Ngo Thanh and Nagahara, Hajime and Sagawa, Ryusuke and Mukaigawa, Yasuhiro and Yagi, Yasushi},
journal = {IEEE Transactions on Signal Processing},
keywords = {Phase,dynamic time warping,quasi-periodic signal},
number = {8},
pages = {2066--2079},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Phase estimation of a single quasi-periodic signal}},
volume = {62},
year = {2014}
}

@article{Mudenagudi2011,
abstract = {We address the problem of super-resolution—obtaining high-resolution images and videos from multiple low-resolution inputs. The increased resolution can be in spatial or temporal dimensions, or even in both. We present a unified framework which uses a generative model of the imaging process and can address spatial super-resolution, space-time super-resolution, image deconvolution, single-image expansion, removal of noise, and image restoration. We model a high-resolution image or video as a Markov random field and use maximum a posteriori estimate as the final solution using graph-cut optimization technique. We derive insights into what super-resolution magnification factors are possible and the conditions necessary for super-resolution. We demonstrate spatial super-resolution reconstruction results with magnifications higher than predicted limits of magnification. We also formulate a scheme for selective super-resolution reconstruction of videos to obtain simultaneous increase of resolutions in both spatial and temporal directions. We show that it is possible to achieve space-time magnification factors beyond what has been suggested in the literature by selectively applying super-resolution constraints. We present results on both synthetic and real input sequences.},
author = {Mudenagudi, Uma and Banerjee, Subhashis and Kalra, Prem Kumar},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Markov random field (MRF),Super-resolution,graph-cut,maximum a posteriori (MAP),minimization,nonlinear,space-time},
number = {5},
pages = {995--1008},
pmid = {20733227},
title = {{Space-time super-resolution using graph-cut optimization}},
volume = {33},
year = {2011}
}

@article{Nasrollahi2014,
author = {Nasrollahi, Kamal and Moeslund, ThomasB.},
doi = {10.1007/s00138-014-0623-4},
issn = {0932-8092},
journal = {Machine Vision and Applications},
keywords = {Hallucination,Reconstruction,Regularization,Super-resolution},
language = {English},
number = {6},
pages = {1423--1468},
publisher = {Springer Berlin Heidelberg},
title = {{Super-resolution: a comprehensive survey}},
volume = {25},
year = {2014}
}

@article{Oren-Grinberg2013,
abstract = {OBJECTIVE: Portable ultrasound is now used routinely in many ICUs for various clinical applications. Echocardiography performed by noncardiologists, both transesophageal and transthoracic, has evolved to broad applications in diagnosis, monitoring, and management of critically ill patients. This review provides a current update on focused critical care echocardiography for the management of critically ill patients.$\backslash$n$\backslash$nMETHOD: Source data were obtained from a PubMed search of the medical literature, including the PubMed "related articles" search methodology.$\backslash$n$\backslash$nSUMMARY AND CONCLUSIONS: Although studies demonstrating improved clinical outcomes for critically ill patients managed by focused critical care echocardiography are generally lacking, there is evidence to suggest that some intermediate outcomes are improved. Furthermore, noncardiologists can learn focused critical care echocardiography and adequately interpret the information obtained. Noncardiologists can also successfully incorporate focused critical care echocardiography into advanced cardiopulmonary life support. Formal training and proctoring are important for safe application of focused critical care echocardiography in clinical practice. Further outcomes-based research is urgently needed to evaluate the efficacy of focused critical care echocardiography.},
author = {Oren-Grinberg, Achikam and Talmor, Daniel and Brown, Samuel M},
doi = {10.1097/CCM.0b013e31829e4dc5},
issn = {1530-0293},
journal = {Critical care medicine},
keywords = {Cardiopulmonary Resuscitation,Critical Care,Critical Care: methods,Echocardiography,Echocardiography: methods,Humans,Monitoring,Physiologic,Point-of-Care Systems,Transesophageal},
pages = {2618--26},
pmid = {23989172},
title = {{Focused critical care echocardiography.}},
volume = {41},
year = {2013}
}

@article{Scholten2005,
abstract = {RATIONALE, AIMS AND OBJECTIVES: Technological progress in recent years has made it possible that ultrasound industry can now offer affordable, portable and battery-operated ultrasound systems the size of a laptop computer. The purpose of this study was to compare these hand-carried ultrasound instruments with standard echocardiography in order to investigate the facility of a rapid bedside diagnosis in patients with suspected or known cardiovascular disease. METHODS: Fifty consecutive patients were studied with miniaturized ultrasound equipment (SonoHeart) and a conventional scanner (Acuson Sequoia) in a blinded manner. All studies were performed by three board-certified cardiologists skilled and experienced in echocardiographic practice. Investigators were not aware of any previous medical reports. RESULTS: With the new system, adequate images could be obtained in all patients. Left ventricular and left atrial diameters measured with the hand-held system correlated well with those obtained with conventional scanning: r = 0.87, mean difference 3.12 +/- 2.7 mm and r = 0.84, mean difference 2.8 + 2.4 mm, respectively. The presence of left ventricular dysfunction, regional wall motion abnormalities, relevant valvular regurgitation (moderate or more) or valve stenosis was correctly diagnosed in all patients. However, there was a tendency towards underestimating the extent of wall motion abnormalities particularly in patients difficult to image. Discrepancies also frequently occurred in patients with trivial or mild regurgitation, where false-positive and false-negative findings were described. CONCLUSION: Currently available hand-held echocardiography systems can facilitate rapid bedside diagnosis and patient screening. However, this recent development in echocardiography also raises a number of questions and its actual impact on general clinical practice still remains to be evaluated.},
author = {Scholten, Christine and Rosenhek, Raphael and Binder, Thomas and Zehetgruber, Manfred and Maurer, Gerald and Baumgartner, Helmut},
doi = {10.1111/j.1365-2753.2004.00506.x},
isbn = {1356-1294 (Print)},
issn = {13561294},
journal = {Journal of Evaluation in Clinical Practice},
keywords = {Hand-held echocardiography,New technologies,Ultrasound devices},
pages = {67--72},
pmid = {15660539},
title = {{Hand-held miniaturized cardiac ultrasound instruments for rapid and effective bedside diagnosis and patient screening}},
volume = {11},
year = {2005}
}

@inproceedings{Shahar2011,
abstract = {Spatial Super Resolution (SR) aims to recover fine image details, smaller than a pixel size. Temporal SR aims to recover rapid dynamic events that occur faster than the video frame-rate, and are therefore invisible or seen incorrectly in the video sequence. Previous methods for Space-Time SR combined information from multiple video recordings of the same dynamic scene. In this paper we show how this can be done from a single video recording. Our approach is based on the observation that small space-time patches (\&\#x2018;ST-patches\&\#x2019;, e.g., 5\&\#x00D7;5\&\#x00D7;3) of a single \&\#x2018;natural video\&\#x2019;, recur many times inside the same video sequence at multiple spatio-temporal scales. We statistically explore the degree of these ST-patch recurrences inside \&\#x2018;natural videos\&\#x2019;, and show that this is a very strong statistical phenomenon. Space-time SR is obtained by combining information from multiple ST-patches at sub-frame accuracy. We show how finding similar ST-patches can be done both efficiently (with a randomized-based search in space-time), and at sub-frame accuracy (despite severe motion aliasing). Our approach is particularly useful for temporal SR, resolving both severe motion aliasing and severe motion blur in complex \&\#x2018;natural videos\&\#x2019;.},
author = {Shahar, Oded and Faktor, Alon and Irani, Michal},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
issn = {10636919},
pages = {3353--3360},
title = {{Space-time super-resolution from a single video}},
year = {2011}
}

@article{Shechtman2005,
abstract = {We propose a method for constructing a video sequence of high space-time resolution by combining information from multiple low-resolution video sequences of the same dynamic scene. Super-resolution is performed simultaneously in time and in space. By "temporal super-resolution," we mean recovering rapid dynamic events that occur faster than regular frame-rate. Such dynamic events are not visible (or else are observed incorrectly) in any of the input sequences, even if these are played in "slow-motion." The spatial and temporal dimensions are very different in nature, yet are interrelated. This leads to interesting visual trade-offs in time and space and to new video applications. These include: 1) treatment of spatial artifacts (e.g., motion-blur) by increasing the temporal resolution and 2) combination of input sequences of different space-time resolutions (e.g., NTSC, PAL, and even high quality still images) to generate a high quality video sequence. We further analyze and compare characteristics of temporal super-resolution to those of spatial super-resolution. These include: How many video cameras are needed to obtain increased resolution? What is the upper bound on resolution improvement via super-resolution? What is the temporal analogue to the spatial "ringing" effect?},
author = {Shechtman, Eli and Caspi, Yaron and Irani, Michal},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Fast cameras,High-quality video,Motion aliasing,Motion blur,Space-time analysis,Super-resolution,Temporal resolution},
number = {4},
pages = {531--545},
pmid = {15794159},
title = {{Space-time super-resolution}},
volume = {27},
year = {2005}
}

@article{Weekes2011,
abstract = {Emergency echocardiography refers to the use of cardiac ultrasound to address critical and time-sensitive clinical questions during the initial evaluation and treatment of the critically ill patient presenting to the emergency department. The information obtained can be pivotal to a physician's clinical decision making and can guide further diagnostic or therapeutic interventions. This article provides an evidence-based discussion of the common uses of emergency transthoracic echocardiography, as well as its benefits and limitations in the current practice of emergency medicine. ?? 2011 Elsevier Inc.},
author = {Weekes, Anthony J. and Quirke, Dale P.},
doi = {10.1016/j.emc.2011.08.002},
isbn = {0733-8627},
issn = {07338627},
journal = {Emergency Medicine Clinics of North America},
keywords = {Cardiac ultrasound,Emergency echocardiography,Emergency medicine,Focused cardiac ultrasound,Point-of-care cardiac ultrasound},
pages = {759--787},
pmid = {1732097},
title = {{Emergency echocardiography}},
volume = {29},
year = {2011}
}

@article{Wiley2014,
abstract = {In 1903, Dr. William Osler advocated for reform of medical education to emphasize bedside teaching, recommending “no teaching without a patient for a text and the best teaching is that taught by the patient himself” (1). More than a century later, new voices in the profession echo that sentiment, suggesting that diagnosis has again strayed from the bedside. Some propose that technology has usurped the clinical examination at the expense of patient care and the cognitive development of practitioners. Proponents of bedside medicine lament that ward rounds have been reduced to examining a patient's electronic medical record and clicking computerized order sets based on results of myriad prior diagnostic tests.},
annote = {10.1016/j.jacc.2014.05.011},
author = {Wiley, Brandon and Mohanty, Bibhu},
issn = {0735-1097},
journal = {Journal of the American College of Cardiology},
month = jul,
number = {2},
pages = {229--230},
title = {{Handheld Ultrasound and Diagnosis of Cardiovascular Disease at the Bedside}},
volume = {64},
year = {2014}
}