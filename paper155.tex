\documentclass[runningheads,a4paper]{llncs}

%
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{url}
\usepackage{graphicx}
\usepackage{multirow}
%
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{arg}\operatorname{min}}\;}
%
\mathchardef\mhyphen="2D
\raggedbottom 
%
% Allow easy processing of labeled images in figures
\newcounter{lfigcounter}
\newenvironment{IonTab}{\begin{table}[htb]}{\end{table}}
\newenvironment{IonFig}{\setcounter{lfigcounter}{1}\begin{figure}} {\end{figure}}
\newenvironment{IonFigH}{\setcounter{lfigcounter}{1}\begin{figure}[h]}{\end{figure}}
\newenvironment{IonFigT}{\setcounter{lfigcounter}{1}\begin{figure}[!t]}{\end{figure}}
\newenvironment{IonFigB}{\setcounter{lfigcounter}{1}\begin{figure}[b]}{\end{figure}}
\def\ionbox#1{\makebox[#1]{(\alph{lfigcounter})}\stepcounter{lfigcounter}}
%
\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{An Image-based method for phase estimation, gating and temporal super-resolution of \\cardiac ultrasound}

% a short form should be given in case it is too long for the running head
\titlerunning{Image-based Phase Estimation Method for Cardiac Ultrasound}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%

% anonymous stuff
\author{*}
\authorrunning{*}   
\tocauthor{*}
\institute{*}

\maketitle

\begin{abstract}
In this paper, we present a novel image-based method for the estimation of instantaneous cardiac and respiratory phases from cardiac ultrasound videos and demonstrate its utility in gating and temporal super-resolution. We first use a novel strategy based on inter-frame similarity to transform the complex high-dimensional periodic cardiac ultrasound image sequence into a 1D time series with the same periodicity characteristics.  Next, we use a trend extraction technique to decompose this time series into a  trend component encoding respiratory motion alone and a residual component encoding the beating heart motion along. Next, we use the Hilbert transform to estimate the instantaneous cardiac and respiratory phases of each frame from these signals. Next, we present a robust non-parametric regression technique that uses these phase estimates to gate out video frames predominantly influenced by respiratory motion. Lastly, we use a kernel regression with a novel kernel to learn an image manifold parameterized by instantaneous cardiac phase that can be sampled to generate a single-cycle video at a higher temporal-resolution. We demonstrate and validate our methods using cardiac ultrasound videos and associated ECG recordings of 6 mice.
%\keywords{Cardiac, Ultrasound, Phase estimation, Gating, Temporal super-resolution}
\end{abstract}

%\vspace{-0.5cm}
\section{Introduction}
\label{sec:intro}
%
Ultrasound is emerging as an increasingly effective tool for rapid non-invasive visual assessment of cardiac structure and function. 
%

%\vspace{-0.5cm}
\section{Method}
\label{sec:method}
%
In this section, we present the theory underlying the proposed methods for instantaneous phase estimation, gating and temporal super-resolution of cardiac ultrasound videos. Specifically, we begin by describing our method for the estimation of instantaneous cardiac and respiratory phases in Section \ref{sec:method:phase_estimation}. We then present a robust method that uses these phase estimates to gate out video frames predominantly influenced by respiratory motion in Section \ref{sec:method:gating}. Finally, in Section \ref{sec:method:super_resolution}, we present a kernel regression method that uses the phase-tagged image sequence to reconstruct a single-period video at higher-temporal resolution. 
%
%
\begin{IonFigT}
\centering
%
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/ecg_instaphase_overlay.png}\\
\ionbox{5.0in}\\
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/qrs_peak_to_peak.png}
\ionbox{5.0in}\\
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/instaphase_valley_to_valley.png}
\ionbox{5.0in}\\
%
\caption{Illustration of correspondence between ECG and the instantaneous cardiac phase estimated using the proposed method: (a) ECG signal (blue) and the cardiac phase estimated using our method using only image data. Also shown are the peaks of the QRS complex (pink circle) and the minima of the estimated cardiac phase (black circle) that correspond to the QRS peaks, (b) Five video frames evenly spaced in time between the first and second QRS peaks of the ECG signal constituting one cardiac cycle, and (c) Five video frames evenly spaced in time between first and second minima of the estimated cardiac phase constituting one cardiac cycle.}
\label{fig:instaphase_vs_ecg}
\end{IonFigT}
%\vspace{-0.5cm}
\subsection{Estimation of instantaneous cardiac and respiratory phases}
\label{sec:method:phase_estimation}
%
\begin{IonFigT}
\centering
%
\includegraphics[width=4.75in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/simMat.png}
\ionbox{1.6in}\ionbox{1.6in}\ionbox{1.6in}\\
\includegraphics[width=4.75in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/season_trend_decomposition.png}
\ionbox{4.75in}\\
\includegraphics[width=4.75in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/periodogram.png}
\ionbox{4.75in}\\
\includegraphics[width=4.75in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/instantaneous_phase.png}
\ionbox{4.75in}\\
%
\caption{Illustration of the proposed phase estimation method: (a) Inter-frame similarity matrix, (b) Trend component corresponding to the respiratory motion, (c) Seasonal component corresponding to the beating heart motion, (d) The similarity profile chosen for phase estimation along with the associated trend/respiration and seasonal/heart-beat components, (e) Periodogram of the heart-beat and respiration components along with the periodicity characteristics such as frequency and cycle duration, and (f) Instantaneous phase of the heart-beat and respiration components.}
\label{fig:phase_estimation}
\end{IonFigT}
%
While there have been numerous efforts for the estimation of instantaneous phase and/or frequency in periodic univariate time series data (wherein a single-variable is measured at each time point)\cite{Boashash1992,Lu2013,Luo2003}, there are not many methods that tackle this problem in a multivariate setting which is the case with periodic cardiac ultrasound videos wherein several thousands of variables (intensities of pixels) could be measured at each time point. Our strategy was to find a way to simplify this seemingly complex multi-variate problem by transforming it into a univariate one and take advantage of existing univariate methods to solve the problem at hand. 

	We first compute the similarity between all pairs of frames in the given periodic image sequence containing $N$ images/frames to create a matrix $A \in R^{N \times N}$ where in the element $A(i,j)$ is equal to the similarity between the $i^{th}$ and $j^{th}$ frames of the given sequence. Here in, we use normalization correlation also known as the Pearson correlation coefficient to quantify inter-frame similarity but, in principle, any of the similarity metrics used in image registration algorithms \cite{Goshtasby2012} can potentially be chosen. Each row in the inter-frame similarity matrix $A$ can now be seen as a univariate time series that measures the similarity of the corresponding frame in the image sequence with all other frames. If the similarity metric is chosen with care and if the corresponding frame is not significantly corrupted we can expect this time series to encompass the predominant periodicity characteristics of the original image sequence. Two kinds of periodic motion are present in cardiac ultrasound videos, one corresponding to the beating heart motion and the other corresponding to respiratory motion. Figure \ref{fig:phase_estimation}(a) shows the inter-frame similarity matrix of one of our cardiac ultrasound videos computed using the normalized correlation metric wherein these two sources of periodicity can be clearly observed in the frame similarity signal of many rows/columns. 

	Next, we use a trend extraction technique~\cite{Alexandrov2012} called the Hodrick-Prescott (HP) filter~\cite{Hodrick1997}, widely used in econometrics, to decompose the frame similarity signal $u(t)$ corresponding to each row of $A$ into a sum of two components: (i) Trend component $\tau_{resp}(t)$ encompassing the periodicity characteristic of only the lower-frequency respiratory motion, and (ii) Residual component $r_{heart}(t)$ encompassing the periodicity characteristic of only the higher-frequency beating heart motion. The HP filter performs the decomposition of $u(t) = \tau_{resp}(t) + r_{heart}(t)$ by solving the following optimization problem:
\begin{equation}	
\argmin{\tau(t)} \left[ \sum_{t=1}^{N}  \left(u(t) - \tau_{resp}(t) \right)^2  + \lambda \sum_{t=1}^{N-1} \left( \nabla^2 \tau_{resp}(t) \right)^2 \right] 
\end{equation}
where $\nabla^2\tau_{resp}(t) = \tau_{resp}(t+1) - 2 \tau_{resp}(t) + \tau_{resp}(t-1)$ is the second-order difference or derivative that penalizes curvature of the trend signal. We use a ridge-regression implementation of the HP filter~\cite{Yamada2015} with $\lambda=6400$. Let $A_{resp}$ and $A_{heart}$ be the matrices whose rows contain the trend/respiratory and residual/heart-beat components, respectively, of the frame similarity signals in the corresponding rows of the similarity matrix $A$. Figures~\ref{fig:phase_estimation}(b,c) show the trend $A_{res[}$ and residual $A_{heart}$ matrices for one of our cardiac ultrasound videos. To minimize the effect of any noise on phase estimation, we pick frame similarity signal corresponding to the row of $A_{heart}$ whose periodogram or power-frequency distribution has minimum entropy. Let $\hat{u}(t)$ be the chosen frame similarity signal and let $\hat{\tau}_{resp}(t)$ and $\hat{r}_{heart}(t)$  be its associated trend/respiration and residual/heart-beat component signals, respectively. Figure~\ref{fig:phase_estimation}(d) shows the selected frame similarity signal (blue) along with the associated trend/respiration (pink) and residual/heart-beat (green) components. Figure~\ref{fig:phase_estimation}(e) shows the periodogram of these two components. Through Figures~\ref{fig:phase_estimation}(b-e), notice how well the two periodic sources have been decoupled from the raw frame similarity signal. Also, in Figure~\ref{fig:phase_estimation}, notice that most of the energy in the periodogram or power-frequency distribution of the respiration and heart-beat components is concentrated within a narrow frequency band. Furthermore, notice how these 1D signals capture the periodicity characteristics (e.g. frequency in beats-per-minute (bpm), period or cycle duration in frames, number of cycles) of the respective sources of motion in the input high-dimensional periodic image sequence.  
		
	Next, considering the narrow-band nature of the derived trend/respiratory and residual/heart-beat signals, we use the Hilbert transform~\cite{Lu2013} to estimate the instantaneous phase of each frame. Specifically, we compute the instantaneous intra-period phase $\phi(t) \in \left [  -\pi, \pi\right )$ of the periodic time series $x(t)$ using its Hilbert transform $H_x(t)$ as follows:
\begin{equation}
\phi(t) = arctan \left( \frac{H_x(t)}{x(t)}\right)
\end{equation} 
and map $\phi(t)$ from the range $\left [  -\pi, \pi\right )$ to $\left [  0, 1\right )$. Let $\hat{\phi}_{heart}(t)$ and $\hat{\phi}_{resp}(t)$ denote the instantaneous cardiac and respiratory phases computed from the trend/respiration $\hat{\tau}_{resp}(t)$ and residual/heart-beat $\hat{r}_{heart}(t)$ signals, respectively, using the aforementioned approach. Figure~\ref{fig:phase_estimation}(f) shows the instantaneous cardiac and respiratory phases computed from the heart-beat and respiration signals in in Figure~\ref{fig:phase_estimation}(d). 

%\vspace{-0.5cm}
\subsection{Gating out respiratory frames}
\label{sec:method:gating}
%
Once the instantaneous cardiac and respiratory phases of each frame has been estimated, it can be used to facilitate the extraction of quantitative measurements from a desired part/point of the periodic cycle, a process commonly referred to as gating. In this section, we present a robust two-step method that uses these phase estimates to gate out video frames predominantly influenced by respiratory motion.

	In the first step, based on the observation that the predominant influence of respiratory motion occurs around the troughs/minima of the trend/respiration signal $\hat{\tau}_{resp}(t)$ (see pink curve in Fig.~\ref{fig:phase_estimation}(d)) corresponding to the respiratory phase $\hat{\phi}_{resp}(t) = 0$, we perform a rough initial gating by discarding the frames $F_{cutoff} = \left \{ t \mid \hat{\phi}_{resp}(t) < c \parallel \hat{\phi}_{resp}(t) > (1 - c) \right \}$ whose respiratory phase distance from $\hat{\phi}_{resp}(t) = 0$ is below a specified cutoff value $c$ that we set to 0.2. Figure~\ref{fig:respiratory_gating}(a) shows the discarded frames $F_{cutoff}$ overlaid (blue circles) on the trend/respiration $\hat{\tau}_{resp}(t)$, residual/heart-beat  $\hat{r}_{heart}(t)$, and respiratory phase $\hat{\phi}_{resp}(t)$ signals.
	
	In the second step, we learn a robust mapping $S(\phi) : \left [  0, 1\right ) \to R$ from cardiac phase to the residual/heart-beat component of the frame similarity signal by fitting a robust non-parametric regression model called Locally weighted regression (LOESS) to the dataset $\left \{ \left(\hat{\phi}_{heart}(t), \hat{r}_{heart}(t) \right) \mid t \notin F_{cutoff}  \right \}$ containing the pair of the cardiac phase $\hat{\phi}_{heart}(t)$ and residual/heart-beat $\hat{r}_{heart}(t)$ signal values of all frames that do not belong to the set of frames $F_{cutoff}$ discarded in the first step above. Next, we compute the median absolution value $\gamma_{MAD}$ of the difference between the LOESS fit $S( \hat{\phi}_{heart}(t) )$ and residual/heart-beat signal $\hat{r}_{heart}(t)$ for all frames as a robust estimate of the dispersion of non-respiratory frames around the LOESS fit. Lastly, we gate out all frames $F_{resp} = \left \{ t \; \big\lvert \; \lvert S( \hat{\phi}_{heart}(t) ) - \hat{r}_{heart}(t)  \rvert   > k \times \gamma_{mad}  \right \}$ for which the difference between the LOESS fit and heart-beat signal value is greater than $k \times \gamma_{mad}$ (we set $k = 2.0$).	
%
\begin{IonFigT}
\centering
%
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/respiratory_phase_gating.png}
\ionbox{5.0in}\\
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/robust_lowess_gating.png}
\ionbox{5.0in}\\
%
\caption{Illustration of our method for gating out respiratory frames: (a) Frames $F_{cutoff}$ discarded (blue circles) in the first step overlaid with the trend/respiration, residual/heart-beat, and instantaneous respiratory phase signals (b) }
\label{fig:respiratory_gating}
\end{IonFigT}
%
%\vspace{-0.5cm}
\subsection{Learning to reconstruct image at any cardiac phase}
\label{sec:method:super_resolution}
%
Once the instantaneous cardiac phase of each frame has been estimated, it can be used to enable spatio-temporal super-resolution by considering the set of images within each period of a periodic image sequence as distinct observations of the same data. In this section, we present a method that uses a phase-tagged periodic image sequence to reconstruct a single-period video at a higher temporal resolution. 
	
Given a de-noised periodic sequence $\{L_1, ..., L_n\}$ of $n$ images (with $m$ pixels each) along with their estimated intra-period phases $\{\phi_1, ..., \phi_n\}$, we first use Nadarya-Watson kernel regression\cite{Bishop2006} to construct a phase-parameterized image manifold in the form of a function $M(\phi): [0, 1) \to R^m $ that maps any intra-period phase $\phi$ to an image as follows:
\begin{equation}
M(\phi) = \frac{\sum_{i = 1}^{n} K(\phi, \phi_i) L_i}{\sum_{i = 1}^{n} K(\phi, \phi_i)} 
\end{equation}
where in we define the kernel $K$ using a gaussian with standard-deviation $\sigma$ equal to a multiple of the average distance between consecutive phases after sorting them. Note that, we account for the periodic nature of the intra-period phase whenever we measure distance between two phase values. A single-period video can now be reconstructed by sampling the manifold $M(\phi)$ at any desired resolution from the range $[0, 1)$ of intra-period phase. Note that the aformentioned process will facilitate temporal super-resolution only if the set of images observed in each distinct period of the given image sequence differ in intra-period phase by some non-zero amount less than its temporal sampling interval. Also, the amount of temporal super-resolution possible will depend both on the number of periods observed and the maximum amount by which one can expect the images to be perturbed in phase across observations. 
%\vspace{-0.5cm}
\section{Results}
\label{sec:results}
%
%
\begin{IonFigT}
\centering
%
\includegraphics[width=5.0in]{figures/decoded/2015-07-27-10-36-06_2015-07-15-16-56-16_1.raw.bmode/phaseordered.png}
\ionbox{5.0in}\\
%
\caption{Visualization of m-mode frames ordered by estimated cardiac phase}
\label{fig:phase_ordering}
\end{IonFigT}
%
%
%\vspace{-0.5cm}
\section{Discussion and future work}
\label{sec:discussion}
%


%
%\vspace{-0.5cm}
\bibliographystyle{splncs03}
\bibliography{library}
\end{document}







